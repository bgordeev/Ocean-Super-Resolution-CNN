{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ocean SST Super-Resolution with CNNs\n",
    "\n",
    "This notebook demonstrates the complete pipeline for training a CNN-based super-resolution model for Sea Surface Temperature (SST) data.\n",
    "\n",
    "## Contents\n",
    "1. Setup and Imports\n",
    "2. Data Loading and Preprocessing\n",
    "3. Model Definition\n",
    "4. Training\n",
    "5. Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    \"\"\"Load and process a single image.\"\"\"\n",
    "    img = Image.open(file_path)\n",
    "    img = img.convert('RGB')\n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file paths - update these paths to match your data location\n",
    "print(\"Loading file paths...\")\n",
    "low_res_paths = glob.glob(\"../data/patches/low_res/*/*.png\")\n",
    "high_res_paths = glob.glob(\"../data/patches/high_res/*/*.png\")\n",
    "\n",
    "print(f\"Found {len(low_res_paths)} low-res images\")\n",
    "print(f\"Found {len(high_res_paths)} high-res images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process images (this may take a while for large datasets)\n",
    "print(\"Processing images...\")\n",
    "low_res_imgs = [process_path(p) for p in tqdm(low_res_paths)]\n",
    "high_res_imgs = [process_path(p) for p in tqdm(high_res_paths)]\n",
    "\n",
    "print(f'Total low_res_imgs: {len(low_res_imgs)}')\n",
    "print(f'Total high_res_imgs: {len(high_res_imgs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to torch tensors and normalize to [0, 1]\n",
    "print(\"Converting to torch tensors...\")\n",
    "x_data = torch.tensor([img.transpose((2, 0, 1)) for img in low_res_imgs], dtype=torch.float32) / 255.0\n",
    "y_data = torch.tensor([img.transpose((2, 0, 1)) for img in high_res_imgs], dtype=torch.float32) / 255.0\n",
    "\n",
    "print(f\"Low-res data shape: {x_data.shape}\")\n",
    "print(f\"High-res data shape: {y_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "print(\"Splitting data...\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.1, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(x_train)}\")\n",
    "print(f\"Test samples: {len(x_test)}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample pair\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "idx = 0\n",
    "axes[0].imshow(x_data[idx].permute(1, 2, 0).numpy())\n",
    "axes[0].set_title(f'Low Resolution ({x_data[idx].shape[1]}×{x_data[idx].shape[2]})')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(y_data[idx].permute(1, 2, 0).numpy())\n",
    "axes[1].set_title(f'High Resolution ({y_data[idx].shape[1]}×{y_data[idx].shape[2]})')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperResolutionModel(nn.Module):\n",
    "    \"\"\"CNN for 5× super-resolution of SST images.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SuperResolutionModel, self).__init__()\n",
    "        self.initial_upsample = nn.Upsample(scale_factor=5, mode='bilinear', align_corners=True)\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_initial_upsampled = self.initial_upsample(x)\n",
    "        x1 = F.relu(self.conv1(x_initial_upsampled))\n",
    "        x2 = F.relu(self.conv2(x1))\n",
    "        x3 = F.relu(self.conv3(x2) + x1)  # skip connection\n",
    "        x4 = self.conv4(x3) + x_initial_upsampled  # skip connection\n",
    "        return x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and print model\n",
    "model = SuperResolutionModel()\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(model, x, y, epoch):\n",
    "    \"\"\"Visualize model output compared to input and target.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(x.to(device))\n",
    "        output_img = output.squeeze().cpu().permute(1, 2, 0).numpy()\n",
    "        input_img = x.squeeze().permute(1, 2, 0).numpy()\n",
    "        target_img = y.squeeze().permute(1, 2, 0).numpy()\n",
    "        \n",
    "        # Clip values\n",
    "        output_img = np.clip(output_img, 0, 1)\n",
    "        \n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title('Input (Low-Res)')\n",
    "        plt.imshow(input_img)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title('Target (High-Res)')\n",
    "        plt.imshow(target_img)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title('Model Output')\n",
    "        plt.imshow(output_img)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.suptitle(f'Epoch {epoch}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training history\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "print(\"Training model...\")\n",
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{n_epochs}')\n",
    "    for x_batch, y_batch in progress_bar:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': f'{loss.item():.6f}'})\n",
    "    \n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            outputs = model(x_batch)\n",
    "            test_loss += criterion(outputs, y_batch).item()\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_losses.append(avg_test_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: Train Loss = {avg_train_loss:.6f}, Test Loss = {avg_test_loss:.6f}')\n",
    "    \n",
    "    # Visualize results\n",
    "    visualize_results(model, x_test[0].unsqueeze(0), y_test[0].unsqueeze(0), epoch+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(train_losses)+1), train_losses, 'b-', label='Training Loss')\n",
    "plt.plot(range(1, len(test_losses)+1), test_losses, 'r-', label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Training History')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare multiple samples\n",
    "n_samples = 4\n",
    "fig, axes = plt.subplots(n_samples, 3, figsize=(15, 4*n_samples))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(n_samples):\n",
    "        x = x_test[i].unsqueeze(0).to(device)\n",
    "        y = y_test[i]\n",
    "        output = model(x).squeeze().cpu()\n",
    "        \n",
    "        axes[i, 0].imshow(x_test[i].permute(1, 2, 0).numpy())\n",
    "        axes[i, 0].set_title('Input')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(y.permute(1, 2, 0).numpy())\n",
    "        axes[i, 1].set_title('Target')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        axes[i, 2].imshow(np.clip(output.permute(1, 2, 0).numpy(), 0, 1))\n",
    "        axes[i, 2].set_title('Output')\n",
    "        axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'sst_superres_model.pth')\n",
    "print(\"Model saved to sst_superres_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "1. Loaded and preprocessed SST patch data\n",
    "2. Defined a CNN architecture for 5× super-resolution\n",
    "3. Trained the model using MSE loss\n",
    "4. Visualized the results\n",
    "\n",
    "The model learns to enhance low-resolution SST images, though some limitations exist (blurriness, edge artifacts) that could be addressed with more advanced architectures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
